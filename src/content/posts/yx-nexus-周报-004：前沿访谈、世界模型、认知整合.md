---
title: YX Nexus 周报 004：前沿访谈、世界模型、认知整合
publishDate: 2025-06-08 22:51:00
featuredImage: /uploads/chatgpt-image-2025年6月9日-16_20_39.png
tags:
  - 周报
---
本周主题主要聚焦在AI领域的**高质量内容输入、前沿思想访谈、个人认知反思等**

- - -

### 01 分享

1.这周首推[对阶跃星辰首席科学家张祥雨的访谈](https://www.xiaoyuzhoufm.com/episode/683d2ceb38dcc57c641a7d0f)，其同时也被很多人认为是华人AI科学家最厉害一批。

虽说是访谈，更多的是祥雨老师对于**个人研究、团队探索、行业前沿的认知陈述与探索回顾**。涵盖了计算机视觉（CV）方面的探索、o1类推理模型的认识与自我团队反思、多模态领域的进展与未来即将到来的“GPT-4"时刻、关于下一代agent的”在线学习”与“自主学习”、对于未来的乐观...

为我带来很多启发，我尤其体会到祥雨老师的**科学精神**。

形而上的抽象思考远不如实际的求真与实践。音质的瑕疵不会遮掩研究前沿的行业洞察与深度探索。

- - -

2.DeepMind 一篇论文：[《通用智能体需要世界模型》](https://arxiv.org/pdf/2506.01622)

* 从理论上雄辩地证明，没有通向通用智能的“无模型（Model-Free）”捷径。 任何想要在复杂世界中灵活行事的AI，都无法回避学习和构建一个“**世界模型**”的根本性挑战。这里的世界模型是一个预测性的、动态的“物理引擎”。这个引擎的本质，是论文中反复提及的环境转移函数的近似。
* 论文对于“涌现”的一些探讨，给出了一个强有力的解释：这并非魔法，而是模型在海量训练任务中，为了“做得更好”（**最小化遗憾**），被“强迫”着在内部学习了一个越来越准确的、关于世界运行规律的“隐性世界模型”。“涌现”是“内在建模”的必然结果。
* 从理论上保证了，任何有能力的AI，其“内心世界”在原则上都是可以被“**反向工程**”出来的。 我们可以通过分析其行为策略。
* 创造AGI的难度，至少与学习一个近乎完美的“世界模型”一样巨大，甚至可能更高。

进一步探讨：[通用智能体需要世界模型——DeepMind论文问答](/posts/20250608214700-deepmind)

- - -

3.我对于一些模型的使用体验分享，[AI 模型使用的思考与分享：智能与体验](/posts/20250606231400)

> 当我需要一个高效的执行者，或需要极致的个性化体验时，我会选择`4o`；
> 当我想进行广度探索，或需要系统的知识学习时，我会求助于`Gemini`；
> 而当我想进行严肃的思辨，或需要深层次的灵感碰撞时，我会去找`o3`。
>
> 我们真正需要的，不是一个万能的“伙伴”或“工具”，而是提升我们自己——成为那个能够洞察不同AI特质，能够定义问题、拆解任务、评估结果，并最终为所有决策负责的“指挥家”和“架构师”。

### 02 访谈

4.红杉对 Paid.ai CEO Manny Media 的对谈:

* 关于 paid.ai 以及可能的未来 agent 的商业模式

  > Paid 是 AI 公司的商业引擎。我们帮助 AI 公司搭建完整的后端运营系统：从定价、计费、开票、营收确认，到收入管理、毛利管理、供应商管理等全流程。我们的目标是帮你**理解单位经济**（unit economics）模型，并能持续运行你的业务。
  >
  > Agent 的总成本包括云计算、LLM 调用费用，以及各种插件、接口、数据处理和语音合成等服务的成本。这些外围支出正在显著推高整体运营成本。
  >
  > paid.ai 以 Agent 的**实际产出**为基础计价，重构 Agent 的收益模型与交易结算网络，为 Agent 经济体打下底层商业引擎。
* 看待**AI应用**以及存在的机会：

  > 现在 AI 应用的趋势，考虑“垂直 vs 通用”，我们正处于“垂直”阶段。也就是说，如果你专注于一个非常具体的问题深挖进去，成为那个领域最顶尖的解决方案，那么你就是在创造巨大价值。
  >
  > 凡是你看到 BPO （业务流程外包）占据很大角色的地方，就是 AI Agents 最适合落地的领域。
  >
  > 真正能让 AI 落地的，是那些没人愿意做的工作。
* 对创业者的**建议**：

  > 回想我在上一家公司时，总想着“我的市场边界在哪”。如果能重来，我会更聚焦，带着明确意图去构建公司，专注打造一个十亿美元规模的解决方案，从那里开始扩展。
  >
  > 如今很多新一代创始人正是这样做：从最小阻力的客户群起步，再逐步放大。唯一风险是，可能过度聚焦于某个小 ICP（理想客户画像），缺乏扩展思维。但聚焦的好处也显而易见——产品路线更清晰，需求更统一，系统更好扩展，增长更自然。早知道这些，我一定会更坚定地只做好一件事。
  >
  > 专注服务一小群用户，别管 TAM（市场总量）有多大，忽略 VC 关于“大市场”的建议。一个“小市场”也能成为“大机会”，前提是你提供卓越体验。
* 推荐的一本书：

  > 改变我对 AI 看法的是一本关于统计自然语言处理的老书，作者是 Rich Manning，斯坦福计算机科学课程的必读书目。书中讲了 Markov 链是怎么预测词的，讲了语言建模的早期方法。虽然现在技术已经有了巨大进步，但很多底层思想还是基于那些老理论的。
  >
  > 《Foundations of Statistical Natural Language Processing》
* 对AI的乐观未来：

  > 我觉得其实AGI已经存在了，只是我们还没充分利用它。我们只是还没意识到它已到来。
  >
  > **AI 成为人类想象力的支架**。它会像“把你扛在肩上”的人，让你看得更远、走得更远。我们将能实现以前根本无法想象的事。

- - -

5.Cursor团队的对谈：

* 对于**强化学习在编码方面**工程应用的独到认识：

  > 编码的动作空间要大得多。推理有助于提供大量的行动以得出答案。编码，某种程度上，推理已经包含在答案中，而且为了得到答案，你必须调用多个工具。因此，它不是像生成推理token、生成答案、获得奖励这样，而是看起来像生成一些token、调用一些工具、从这些工具获得响应，并且你可能会迭代多次。所以强化学习（RL），强化学习的形式看起来有点不同，因为现在你必须经历这种多步骤的工具调用过程，并在此之上进行优化。
* 更有趣的是涉及到**写作方面应用RL**：

  > 在模型上进行的后训练往往使它们以一种非常生硬和正式的方式写作。但我不认为那是模型的固有局限。我认为那只是它们被训练成要做的。
  >
  > 为什么不能训练模型来预测下一章节呢？当然可以，你可以改变学习动态，让它开始预测整个序列，而不是预测下一个token。给定书的当前章节，模型应该尝试预测书的整个下一章节，有点像故事的走向。然后你就可以使用某种相似度度量来衡量下一章节与真实章节的相似程度。

很有趣。RL在目标明确的领域适用，我突然想到网文属于高重复、高商业指标、高交互数据的垂直场景，这天然适合 RL。

- - -

6.谢扬，Fellou（AI浏览器） 的创始人：

* 什么是 Agentic System？

  > Agentic System 是由多个模块动态协同构成的“系统智能”，强调结构性架构与组件联动。
* 我们现在训练的所有 Agentic AI 最大的问题是什么？

  > Agentic AI 的参数是固化的，不能动态实时地修改参数，因此每次修改的成本都很高。但 System 允许动态修改，这也是为什么有了模型之后我们还需要做提示词工程，做很多上层封装工作的原因。在我看来，现在大模型只是一个控制单元（Control Unit），我们做的 Agentic System 是除开 Control Unit 外所有的链接工作。
* 浏览器中的 Agentic System 如何做得更好？

  > 知识可视化和图形化是未来解决复杂问题的趋势，因为图形能同时调用大脑的多个区域。
  >
  > Z 轴思维模式——利用 X、Y、Z 的象限理解和分析问题
* Agentic System 的未来，人机交互的模式应该是什么？

  > 未来人人都是哲学家，控制模型的宏观思维，而非行为。大模型如果能结合到领域内的形而上，它的能力将被迅速放大。
* 人机协作应该是什么样的关系？

  > 我认为，人和 Agent 在协作时，Agent 需要理解上下文，需要理解人的行为。所以，我们对 Sandbox 的理解，不只是云端虚拟化，而更强调本地虚拟化。

关于团队：

> 我们现在引入了 Research（研究）团队，我对他们有两个核心要求。
> 首先，产品、工程一起开发产品，用算法和数据解决工程解决不了的问题。
> 其次，**自我革命** —— 推翻现在工程问题的解决方式，重新定义解法。

分享洞见：

> 最近这两三年，我最大的感受是，随着模型的发展速度越来越快，人类的“**高阶哲学思辨能力**”必须被重新重视、重新提升。
>
> 我认为未来的教育可能不再是教人具体做什么事。
>
> 所以我觉得未来人类真正的竞争力，不在于执行层，而在于是否拥有高效的哲学思考能力，是否具备**形而上的认知能力**。这也是我刚才讲的那些背后的逻辑核心，人类要想得更清楚、更深远，而 AI 可以去执行。我认为这是每一个人、每一个团队都必须去认真思考的问题。

### 03 认识

7.美图创始人吴欣鸿在一次内部复盘中说，“这是我们烧了 42 个亿，换来的 3 个领悟。”

> * 战略要与能力匹配；
> * 不能随便消耗资源；
> * 要有核心竞争力。

8.张晓东：[如何做出好产品](https://mp.weixin.qq.com/s/s0hk-0nwtkdk-Dq1eeedAw)

> * 这一切，最初都源自张一鸣的一个认知：**信息获取的问题，只能靠推荐来解决**。
> * 我把张一鸣击碎我的思路称之为张一鸣产品定律：**用户使用产品的收益大于操作成本是产品成功的必要条件。**
> * stay foolish很重要，所以说做产品最好有能力一秒变小白：**切到对这个产品一无所知的状态，然后重新看这个产品，会看到什么。**
> * 乔布斯有个很好的说法：「我对我们决定不做的事，和决定要做的事，同等自豪」
> * 「到最后，一切都归结为品味」一个人擅长一个领域的标志就是这个人在这个领域有很好的品味：知道什么是好，什么是差，知道什么是特别好，什么是特别差。
> * 顺便说一句，优秀的产品体验细节往往都不错，体贴、细腻、漂亮、酷——但这些不是产品成功的必要条件，产品成功的必要条件是：**击中了需求，且没有违反张一鸣产品定律**
> * 在很多公司，很多产品决策是靠产品经理/老板的个人直觉，但在字节，你可以靠科学，在任意时刻，都有无数ab测试在进行，有无数版本的头条抖音TikTok在线上运行，拿到准确数据，持续改进。
> * 字节在打造推荐系统的过程中，有科学方法、有超高标准、有领先的认知判断，有能力打造好产品，然后遇到时代的机遇和运气，这些是我认为字节取得今天成就的原因。

- - -

### 04 个人认知

8."智能，是在有限经验中，通过结构建模与可迁移的意义表征，与环境持续对话、实现目标与自我更新的一种能力。"

9.**连接主义**学会感知与建模，**行为主义**决定如何反应，**符号主义**帮助计划与解释，**控制论**协调一切。

控制论（Cybernetics）是研究“系统如何通过反馈实现控制和自我调节”的跨学科科学。

核心思想是：只要有感知、有反馈、有目标，有调节机制——就可以构成智能行为。

> 连接主义给了模型认知能力，
> 行为主义让它可以被激活与训练，
> 符号主义增强它的逻辑与规划能力，
>
> 但控制论才让这些能力成为一个“有机体” —— 能感知世界、调节行为、追求目标、在反馈中成长

10.现实之所以是“现实”（即现在我们看到的这样），其就是当下的最优解，过度地摧毁这个现实，而不是一点点修正，（比如加尔定律运用到这个层面上），不可避免地存在全局崩溃的可能。

在复杂系统科学中，“现有状态”往往是系统在多轮自我调节之后的局部最优稳定态。系统“可被优化”的正确方式，往往是通过嵌套式修复、渐进式演化，而非全盘重置。

11.[从颠覆到建设：token预测、第一性探讨、概率本质、思考方法论](/posts/20250604115600-token)

> 1. 我们对“认知”基本范畴的定义建立在经验性幻象之上，缺乏第一性支撑；
> 2. token prediction 并非认知的替代品，而可能是认知机制本身的镜像呈现；
> 3. 如果世界的运行机制就是最小化不确定性（=预测误差），那么“生成模型”可能是我们已知最接近自然规律的人工建构形式

12.四点思考反思注意：

* 在追问本质的同时，也要珍视经验与感受。
* 在肯定AI潜力的同时，也要正视其局限与人类的独特性。
* 在探索底层规律的同时，也要警惕过度思辨可能带来的虚无。
* 在看似对立的“主观”与“客观”之间，寻找更圆融、更完整的理解

- - -
