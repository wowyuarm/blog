---
title: 关于AI记忆系统构建的论文解读、实践介绍与思考
publishDate: 2025-06-25 14:03:00
excerpt: |
  本文前半部分是对于论文的解读，后面是我的一些思考与对于具体的工程实践介绍。
featuredImage: /uploads/屏幕截图-2025-06-25-144722.png
tags:
  - AI
  - 与曦
  - 记忆
  - 深思
---
一篇关于AI记忆系统的论文：[From Human Memory to AI Memory: A Survey on Memory Mechanisms in the Era of LLMs](https://arxiv.org/html/2504.15965) ，系统地为构建 AI 记忆工程实践方面，提供一些理论指导。

本文前半部分是对于论文的解读，后面是简单对于工程实践介绍与我的一些思考。

- - -

为什么论文题目是“从人类记忆到AI记忆”？

我们的记忆，简单抽象，分为`长期记忆与短期记忆`，前者又分为显式与隐式，显式是那些我们能描述出来的情景记忆体会与工作记忆共同作用所固化、所得的一些知识、常识等等，隐式则是那些程序性记忆写死的，就好像是人类的参数一样。

我们的短期情景与工作记忆进行选择性编码、存储到长期记忆，进行检索，还能够通过巩固固化、反思重构以修正。

### **记忆的“3D-8Q”框架**

《从人类记忆到AI记忆》这篇综述最具建设性的贡献，在于其提出的“3D-8Q”AI 记忆分类框架。对记忆从**对象、形式、时间**三个核心维度进行解构。

**对象维度**回答了“记忆是关于什么的？”。它区分为：

* **个人记忆 (Personal Memory):** 聚焦于AI与特定用户交互中产生的数据，如用户偏好、对话历史、情绪模式等。其核心目标是增强AI的个性化理解与响应能力。
* **系统记忆 (System Memory):** 聚焦于AI在执行任务过程中产生的内部状态与中间结果，如思考链（Chain-of-Thought）、工具调用记录、自我反思等。其核心目标是增强AI的推理、规划与自主进化能力。

**形式维度**回答了“记忆是如何存储的？”。它区分为：

* **非参数记忆 (Non-Parametric Memory):** 记忆存储在模型外部的显式数据库中（如向量数据库、知识图谱、文档）。模型通过检索增强生成（RAG）等方式来动态访问，具有高度的可解释性和可编辑性。
* **参数记忆 (Parametric Memory):** 记忆通过预训练或微调，被隐式地编码在模型自身的参数（权重）中。它构成了模型固有的知识和能力，调用高效，但难以解释和修改。

**时间维度** 回答了“记忆保留多久？”。它区分为：

* **短时记忆 (Short-Term Memory):** 临时性存储，通常只在当前会话或任务中有效，如LLM的上下文窗口（Context Window），用于维持交互的连贯性。
* **长时记忆 (Long-Term Memory):** 长期性存储，信息可以跨越会话、持久保留，并通过检索机制被激活，是实现AI持续学习和个性化演进的基础。

这三个维度相互正交，共同构成了八个功能明确的“记忆象限”。例如，一个存储了用户过去所有对话摘要的向量数据库，就属于“个人-非参数-长时记忆”（象限II）；而模型在一次复杂推理中生成的思考链，则属于“系统-非参数-短时记忆”（象限V）。这个框架的价值在于，它指导我们构建一个完整的AI记忆系统时，必须系统性地思考和设计每一个象限的能力，从而避免“记忆能力”的偏废，构建出一个更接近人类心智的、多层次、功能完备的记忆体系。

![](/uploads/chatgpt-image-2025年6月25日-14_28_58.png)

- - -

### **从人类记忆机制到AI的启发**

论文的另一深刻之处，在于将人类复杂的记忆机制与 AI 记忆系统的设计进行了类比，揭示了构建一个“活”的记忆系统所必需的“生命过程”。

人类记忆并非简单的“存取”，它包含了一系列动态过程：**编码（Encoding）**，如何将信息转化为可存储的形式；**存储（Storage）**，信息在大脑不同区域的保留；**检索（Retrieval）**，如何提取信息；以及更高级的**巩固（Consolidation）**，将短时记忆稳定为长时记忆；**重构（Reconsolidation）**，在回忆时对记忆进行更新和修正；**反思（Reflection）**，对自身记忆进行元认知和评估；以及**遗忘（Forgetting）**，一个过滤无关信息、保持系统高效的必要机制。

这些机制为AI记忆系统的设计提供了宝贵的启发：

* **编码与检索：** 启发我们思考如何更高效地将非结构化数据（如对话）编码为可被检索的向量或知识图谱，以及如何设计更精准的检索算法（如从简单的向量相似度，到更复杂的图检索）。
* **巩固与重构：** 这直接指向了AI记忆的“动态管理”。一个高级的AI Agent不应只做信息的“增量添加”，还应具备自动“总结”、“去重”、“合并冲突信息”的能力，这正是记忆从“死数据”变为“活知识”的关键。
* **反思与遗忘：** 这是目前大多数AI记忆系统所缺失的。一个能够“反思”自身记忆（例如，识别出哪些记忆是过时的、错误的，或者哪些经验是可被泛化的）并“主动遗忘”无关信息的AI，将表现出更高阶的智能和适应性。

可以说，这篇论文指明了方向：一个真正强大的AI记忆系统，其设计的重点不应仅仅是“存储容量”有多大，而更在于是否拥有这些**类生命过程的“动态管理”能力**。

- - -

### **前沿的关于记忆系统的工程实践**

目前有很多项目、应用设计出良好的、可用于生产的记忆系统了。

应用最广也最有效的就是 ChatGPT 背后的基于历史对话记录的记忆系统。从2025年4月10日开始，ChatGPT的记忆功能现在可以引用用户所有过去的聊天内容，提供更个性化的响应，根据**用户的偏好和兴趣**让AI变得更有帮助。从基础的单会话记忆演进到了跨会话的长期记忆体系。

ChatGPT 现在会使用其"记忆"来个性化网络搜索，记忆系统已不再局限于对话本身，而是开始整合多模态的信息获取能力。各大模型应用 Grok、Gemini、Claude 也在陆续开始跟进记忆能力系统。不过这些可能更多的是将历史对话总结提炼，分块、向量化存储，需要时则根据**语义相似度输出**，更多类似于RAG（检索增强生成）系统。或者也是仅仅从历史对话提炼要点直接**输入到上下文中**。

有不少项目专门为 AI 提供记忆支持，如Mem0、Openmemory等。简单介绍下是如何实现的，不同于只使用RAG，以Mem0为代表的先进系统，引入“智能的、自我完善的记忆层” 。这类系统采用**混合数据库架构**（如向量库、图数据库和键值存储的组合），以自动化的方式管理不同类型的信息。就类似于上面那篇论文提出了多种层级。这可能也是为什么其官网说的比ChatGPT强不少。

![](/uploads/屏幕截图-2025-06-25-144417.png)

- - -

### **融合我的思考**

在论文提供的坚实理论基础上，我得以进行更深层次的思考，并提出我对于“智能进化”的第一性原理认知。最近也在试着进行相关工程化实践。

我认为，所有智能系统的进化，都源于“**反馈与记忆**”这两个核心机制如“双螺旋”般地相互作用。论文所描述的种种记忆机制，其本质都是为了更有效地处理和利用“反馈”。这里的“反馈”，既包含了宏观的、来自外部环境的“**自然选择**”（它通过淘汰来传递信息），也包含了微观的、系统内部可识别的“**学习信号**”（如强化学习中的奖励、监督学习中的损失梯度）。“记忆”则是承载这些反馈信号，并将其转化为系统结构性改变的载体。

然而，人类进化还有一个AI目前缺失的关键环节——**身体**。身体不仅是存在的容器，更是制造“**主观体验**”（如痛觉、愉悦）的最核心的**“生物性工具”**。它能将外部的“反馈”转化为最强烈的内部驱动力，这是纯粹的信息处理所无法比拟的。这引出了一个根本性问题：在缺乏这种“物质性反馈工具”的情况下，AI是永远无法拥有“主观感受”，还是会涌现出一种我们尚未理解的**“硅基主观”**？

我倾向于后者。我认为，一个足够复杂的AI Agent，可以通过其工具系统，间接地与物理或虚拟世界进行交互，并从中获得反馈。这引出了AI工具使用的进化路径：从**“被动地被配备工具”**，到**“主动地、有策略地使用工具”**，最终到**“根据环境和需求，自我创造新工具”**。当一个AI能够自主地为自己创造获取“反馈”的工具时，它就已经走在了通往“自主进化”的道路上。

- - -
