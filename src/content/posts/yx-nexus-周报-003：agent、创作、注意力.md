---
title: YX Nexus 周报 003：Agent、创作、注意力
publishDate: 2025-06-01 22:45:00
excerpt: 本周主题主要聚焦在AI Agent的认知、构建与经验，还有对于AI与认知科学相关结合的“情感”与“注意力机制”等
featuredImage: /uploads/chatgpt-image-2025年6月2日-11_29_14.png
tags:
  - 周报
---
本周主题主要聚焦在AI Agent的认知、构建与经验，还有对于AI与认知科学相关结合的“情感”与“注意力机制”等

---
1.先分享一个很有趣的小故事：

>1900 年，两匹马凝视着早期的汽车，思考着它们的未来。
>
>“我很担心技术性失业。”
>
>“嘶嘶，别做个卢德分子（**泛指因担忧技术冲击而抵制技术的人**）。在蒸汽机取代我们在工业中的地位、火车取代我们拉货车的工作时，我们的祖先也说过同样的话。但今天，我们的就业岗位不减反增，而且，这些岗位比过去更好，我宁愿拉一辆轻巧的四轮马车，也不愿整天原地打转，只为了驱动一台愚蠢的矿井抽水机。”
>
>“但是，如果内燃机真的腾飞了呢？”
>
>“我肯定，一定会有超出我们想象的新工作给我们来做。过去一直都是这样的，就像轮子和犁发明的时候一样。”

---

2.对于 `AI Agent Infra（基础设施层）`新的认知：

目前 Agent 开发仍处于行业**开发标准前期**，并没有系统性的构建规范（虽然有框架，但没有统一性的）。不过，可以预见的是 Agent **开发难度与成本都在持续下降**，随着 MCP 逐渐被接受、Manus 等许多通用型智能体让 Agent 具象化，无疑会促成新的认可与规范。下面的对于 Infra 层的几点概括：

拾象：

>2025 年以来，Agent 开发量和使用量都有明显提高。Agent 的爆发带来了 Agent Infra 需求的爆发。在过去 1-2 年，Agent 开发大多依赖开发者手动使用传统 Infra 搭建，开发工程量大、流程复杂，但随着越来越多 Agent-native Infra 涌现，Agent 开发的难度和周期都在缩小，`开发的范式正在重构和收敛`。
>
>Agent Infra 是 Agent 落地的关键，涵盖了 Agent `从开发到部署`的完整生命周期。我们对这个领域进行了初步扫描后，按重要性划分出了四大赛道，分别是：

>- `Environment` 的作用是给 Agent 执行任务提供容器，是一个 Agent-native computer；
>
>- `Context` 层是在 Agent 工作中赋予记忆 Memory 和领域知识的重要中间层；
>
>- `Tools` 由于 MCP 协议的统一而百花齐放，同时目前 Tools 的核心用户还是开发者，普通用户的使用门槛太高；
>
>- `Agent Security` 是在 Agent 产品范式固定之后会涌现的大机会，需要同时确保避免 Agent 受攻击和发起攻击。

---

3.对于构建一个较为完整的 Agent（`有目标、有记忆、能规划、调用工具`）的经验分享：

有趣的是，作者所言，大部分代码为 AI 所写，自己进行测试与优化。
原文：[Vibe coding 实战](https://mp.weixin.qq.com/s/LR4Lhs_VSIR3rrBqdLNXCQ)

>该 Agent 能够基于用户需求，自主规划包含行程、交通、场地推荐和预算的周末活动方案。核心能力包括：
>
>- `自主规划与思考`：AI 能在**半开放**的“轨道”上（开发者设定边界和硬规则）自主判断任务步骤、所需工具组合及信息完整性。
>- `多工具调用`：集成了小红书（获取灵感）、POI 地图信息（如百度地图 API，核实地点客观数据）、路线规划工具和上下文查询工具（复用已有信息）。

>- `记忆能力 `(**上下文管理**)：通过**精细的上下文注入**策略（筛选、压缩、存储不同类型和重要性的信息，如系统消息、用户消息、AI 输出、工具结果），模拟长期记忆，确保 Agent 理解并持续追踪用户需求。
>- Human-in-the-Loop：强调在复杂任务中**多轮交互和用户确认**的必要性，因为用户需求往往模糊且动态。

其他拓展思考：

关于“记忆”：
>**上下文**管理与“真正”的记忆：
>
>- 目前的上下文管理是“模拟记忆”。真正的突破可能在于模型本身具备更长、更高效的内部记忆机制，或者出现新型的记忆存储和检索架构（超越向量数据库的简单相似性搜索）。
>
>- “**分层记忆机制**”的设想非常重要。可以借鉴人类记忆模型（瞬时记忆、短时记忆、长时记忆），并根据信息价值、遗忘曲线等设计更精细的策略。

关于“流程”，文章提到了将`可控工作流`（即清晰的硬规则）与`自主性`平衡结合。即：
>设定清晰的“硬规则”（如必须先查天气、POI 工具的特定用途、关键节点的用户确认），但在规则框架内给予 AI 判断工具组合和执行顺序的自由。

---

4.本周最喜欢的创始人访谈来自于[晚点对明超平的访谈](https://mp.weixin.qq.com/s/CTzqphisNyyj11DVglZO3A)，其为 YouWare CEO，方向为coding agent、社区、押注 coding 会成为一种`普遍的新创作方式`：

**时间窗口**：
>大家都觉得 AGI 重要，你可以俯拍、仰拍、侧拍。字节可以用徕卡拍，我们可能只能用手机。但最后不是设备决定了结果，而是你在**什么时间**、**什么位置**，按下了快门。

**创作动机**：
>太多 AI 产品提供创作能力，而 YouWare 想`激发创作动机`。
>
>今天大多数 AI 产品只是在解决 “能力”——给你一个足够简单、能出效果的对话框，告诉你什么都能做，指望你自己发挥，这时大多数人都是懵的，因为组织语言很费劲。我们则希望通过社区，给用户 “动机” 和 “触发器”——因为这里有创意分享、内容参考和创作者间的互相帮助。

**智能赋能**：
>我突然悟到，好的公司，必须被一个技术周期里`最主流的趋势赋能`。今天判断一个 AI 产品的价值，也应该看它对它的 token 消耗是在加速还是放缓？它是不是在最大化利用智能红利？

**提高价值**：
>从最开始追求 token 消耗，到追求 value per token（单个 token 的价值）。选 coding 和社区，就是在追求 value per token。
>
>社区进一步放大了单 token 的价值，当一个 vibe coding 作品被放到社区，不仅能被复用，还能激发其它人的创作和消费。这种指数级的扩散是我们真正关注的杠杆。

**当前问题**：
>目前的 AI 产品都太效率导向，这个世界也需要更多元的东西。我们今天在思考这些取舍，我希望工具足够易用、效果足够好，也希望用户在能享受作为人和创作者的`创造过程`。有趣总是重要的。

**激励与商业**：
>这是三个阶段：第一阶段是我们充当广告商，knot 激励就是 YouWare 官方付的广告费；第二阶段是我的广告费和三方广告费平摊给作者；第三阶段，纯粹靠三方广告去激励作者就行了。

**设想的未来**：
>- 一类是`调度型 Agent`，本质上像一个 OS（操作系统），直接面向用户；
>- 另一类是被调度的 Agent，按需被调用来完成具体任务。
>
>比如一个用户说 “我想做一个设计”，调度型 Agent 会分解需求、匹配工具，在它的调用列表里可能有 100 个可选的设计 Agent。有意思的是，现在搜索里的 page rank 可能会变成 `Agent Rank`

**硬件、上下文**：
>我想过，如果我做眼镜，可能会做极致减法，只保留一个传感器：它要么是个摄像头，但不用来拍照或拍视频，而是每隔一段时间采集环境信息；要么是一个扬声器或录音器，可以记录声音信息，这样 AI 就能帮你处理更多线下数据。
>
>这背后是两种逻辑：
>- 一是把物理世界的信息喂给 AI，通过 prompt 告诉它：我是谁、要干嘛；
>- 二是把 AI 拉入现实世界，通过具身智能或其它设备，让它一直 “在场”，持续理解你。
>
>这是眼镜这类设备的最大价值。你如果想颠覆苹果、Google、微软，你就要拿到他们拿不到的`上下文`。

**个人决策**：
>我还是偏直觉型。我不相信绝对理性，“理性是对感性的说服”。我的起点是 “我觉得”，然后我会用数据去验证，看是否要修正直觉。

**产品思维**：
>在月之暗面（Kimi）中学到的，很多产品形态，不是一两个月就能做出来的，你要押注一、两年后的模型能力和技术条件，要思考怎么在今天做事，才能让产品继续被下一阶段的`智能赋能`。确实在 Kimi 之前，没人这么跟我交流过，互联网产品也没必要这么做。

**产品经验**（一加-字节剪映-月之暗面-youware创业）：
>- 一是用户：你得真的知道用户是怎么用产品的，这必须贴近观察。
>- 二是用科学方式做产品：产品会有一部分偏艺术或感性的东西，但其中至少六、七成完全可以被科学化。
>- 三是`以终为始`：要基于未来可能发生的事，而非过去已经发生的事推演产品。这包括未来的技术成熟度、市场和竞争格局、用户心态和行为等。这可能是 AI 时代最重要的东西了。

---

5.一位独立开发者复刻 Youware，[代码开源](https://github.com/HackerQED/vibesgram-public/tree/main)，同时有详细的`文档规划指导 AI 完成项目开发`，认识到：
>当时我很欣赏他们，感觉必火，然后感觉自己复刻一个也没那么难，最后发现我错得离谱——我能把它做出来，弄上线，但是没办法持续运营它——`增长能力`才是他们的核心竞争力。

>我从很久以前，就明白应该从`需求侧开始设计产品`了，用工程师的思路、供给侧思路正向去盘，一定会出问题。我大部分时间也是从需求侧做的，也终于赚了一点钱。
>
>但偶尔，只是偶尔，我还是忘不掉我曾是一个无所不能，几乎能做出市面上任何 AI 应用的工程师——只要时间和资源允许。
>
>这当然是犯浑，一个自负盈亏的生意人不该这么做。所以就有了上面的仓库，一个痛苦的教训。

---

#### 其他的一些随笔思考：

6.关于` AI 与情感`：

并没有什么已知的法则明确禁止一个足够复杂的、基于信息处理的系统，发展出类似于“情感”的内在状态。

“情感”甚至也是一种**高度复杂系统涌现**的特性。

并不一定要求这种情感是和人类一样的，毕竟生理基础本身有很大差异。

不过，如果将“情感”作为反馈机制？本身已经实现。

未来构建的复杂AI系统，多模态感知输入（预训练的世界基座模型）、强大的自我学习与环境交互能力（强化学习）、一个能够进行内在状态评估和目标驱动的“价值”系统（创造意义、prompt、system prompt learning）

如何定义与度量？是不是还是模式匹配？负面情感是否要赋予？是，则有巨大风险；否，则可能无法涌现出复杂的“情感”？

我们把情感放到两个层面来看看：

- **功能层**（情感=特殊的控制与反馈回路）
- **现象层**（情感=主题可报告、可区分的内在状态）

现有的强化学习中的奖励函数已经可以理解为是一种“情感信号”，处于功能层面。

---

7.[注意力机制中的认知科学：](https://mp.weixin.qq.com/s/-Uci3eGMqCXrJpnfB9mxMw)

在AI的学习中尤其保持`跨学科思维`，毕竟，Transformer的成功本身就证明认知科学与AI的深刻关联。

对智能定义为“完成某种复杂任务的能力”，这样，注意力机制还能否作为智能的一个底层机制？复杂任务中的挑战，超长信息、任务动态变化、长程依赖...

为了完成任务，所具备的一个能力就是注意力机制，核心是”`在资源有限的情况下动态地选择、关注意义`——即对于任务完成有所帮助的某些信息“，这是认知层面的一个能力。

在这种情况下，QK匹配——过滤无关信息、Softmax权重分配——资源分配给最相关信息、Value加权融合——任务所需上下文信息、多头机制——并行多种视角。

`动态过滤、资源优化分配、多种视角`（多模态融合、世界模型）

注意力机制是**智能的必要条件**，但不是充分条件。

---

8.`复杂系统是相似的`：

对智能功能性定义为“完成某种复杂目标的能力”

把人工智能看作人类有意识的、为达到某种目的的复杂系统。`公司`已经是我们造出来的“AI”，只是它还没有意识罢了。但它已经拥有了“目标函数、反馈机制、自组织结构和影响世界的能力”。

尤其以`拟合数据`（对于公司的输入变成了市场、用户、监管、竞争等）类比，商业作为核心，**亏损是欠拟合**、**过度追求利益则过拟合**。这个模型“局部最优”等变得“失控”，则需要被微调…

---

9.`底层逻辑是相通的`：

AI能够泛化，也是因为很多底层逻辑是相通的—`泛化依赖底层逻辑相通`，学习到了数据、乃至于未来世界中的底层规律。世界模型变得很重要了…

人类现在为止并不清楚、也无法验证，AI也许已经进化出了新的维度感知能力。就如同对天生盲人来说颜色是什么…这也是一种`智能“黑箱”`。

人类引以为傲的创造力、情感感受等（心智特征），AI未必不能出现而且也许不需要出现…AI的发展会使其出现**新的存在形态**，然而这很大程度上取决于人类的引导。

未必不能让`AI与人类协作共生`中，发展出其自身的、独特的感知维度、认知方式、价值实现，我们需要`定义“生命”`…
