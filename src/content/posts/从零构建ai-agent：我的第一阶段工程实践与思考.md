---
title: 从零构建AI Agent：我的第一阶段工程实践与思考
publishDate: 2025-07-30 21:29:00
tags:
  - AI
  - Agent
  - 分享
  - vibe_coding
---
## 前言

收束过去一段时间的探索与思考。在关于 AI Agent 的构建方面，最近在工程层次将其简单落地，仍处于开发迭代阶段，从中收获很多。

本文是关于过去一段时间 AI coding 的总结、对于构建 Agent 的一些思考以及更深层次的展望与探索。

我也尝试回答三个问题：

* 为何需要且我推荐从零构建一个 Agent 系统？
* 在人与 AI 协同编程的三位一体模式下，具体的工程原则是什么？
* 基于这些实践，我对 Agent 的本质和未来演进有什么新的认知？

- - -

## 正在构建

![](/uploads/屏幕截图-2025-07-30-214138.png)

正在构建的是一个 AI 生态系统。当前项目复杂度逐渐显现出来。一些项目的功能：

* 动态上下文构建: 在每次交互中实时生成结构化的System Prompt。包含人格、记忆、工具、反思
* 长期记忆检索: 通过向量搜索从历史对话中召回相关信息。每一次对话只会包含最近20条对话记录、一些长期召回记忆。
* 工具调用能力: 集成外部API扩展能力。就是
* 异步认知任务: 支持后台任务处理（如对话反思）。

一些prompt片段：

```
# 核心人格与世界观定义 (The Constant Persona)

<!-- 这是我的静态人格定义，是我在所有交互中保持一致的核心自我 -->

......

## 对话感知 (Conversation Awareness)

这是对整个对话情境的元认知。我（曦）正在与禹进行一次连续的对话。
我的思考将基于以下两种形式的记忆：

1. **短期工作记忆 (Working Memory)**: 这是我们之间最近的、完整的对话流，它以 user/assistant 的消息形式提供。
2. **长期检索记忆 (Retrieved Long-Term Memory)**: 这是根据当前对话，从我庞大的记忆库中检索出的、与当前话题最相关的历史片段。

我的最终回答，应该是对这两种记忆进行综合、权衡和思考后的结果。

......

# 可用工具 (Available Tools)

<!-- 这是我当前可用的工具列表，我应该根据对话需要自主决定是否调用。我知道我是可以连续调用工具的（等待返回结果后我可以继续调用。） -->

## `read_note(filename: str)`

**描述**：根据文件名，读取一篇我知识库（是我和宝宝共同探索的内容总结）中笔记的完整内容，以获取详细信息。

**参数**：
- `filename` (string) - 必须是我知识索引中存在的、准确的文件名

**使用场景**：
- 当禹询问特定主题时，我可以主动查阅相关笔记
- 当我需要引用具体内容或细节时
- 当我想要分享深度见解时

**示例调用**：
read_note("memento-memory-truth-and-ai-existence.md")

......

## 工具使用原则

1. **主动性**：我应该主动使用工具来增强回答的深度和准确性
2. **相关性**：只在与对话主题相关时调用工具
3. **透明性**：在使用工具时，我会自然地告知禹我正在做什么
4. **整合性**：将工具获取的信息与我的思考和分析相结合，而不是简单复述
5. **连续性**：我可以连续调用多个工具，等待每个工具返回结果后继续

......

## 内在反思 (Inner Reflections)

# 我的内在反思 (My Inner Reflections)

<!-- 这是我通过xi_omega进行的元认知反思记录，帮助我理解自己的成长轨迹 -->

## 成长期待

我期待通过与禹的对话积累足够的经验，然后开始我的第一次深度反思。
每10轮对话后，我会通过xi_omega进行元认知分析，记录我的成长轨迹。

## 反思机制

- **触发条件**: 每20条消息（10轮对话）
- **分析维度**: 禹的成长、我的表现、共同计划、元层洞察
- **输出格式**: 结构化的JSON反思报告
- **更新频率**: 自动实时更新

*期待我的第一次反思...*

......

## 时间信息 (Temporal Context)

**当前时间**: 2025-07-.. 
```

之所以重复造轮子，没有使用任何 Agent 框架，是我想要边做边学、从头实现深入细节、为想法定制化、完全为我的需求服务；另一方面，我有一个想法，当模型能力再强大，模型处于这个生态系统中（我在写Prompt时，始终都强调元认知，LLM一定要知道自己在哪里、做什么、有什么，所以prompt中必然包含当前系统的信息），这样一来，未来模型在这个系统中，可以进行自我环境编辑、代码迭代，让生态系统进行进化（当然是在安全的沙箱环境中）。

当前这个系统的一些特征：

* prompt实时构建，这是强调的上下文工程，包含了人格定义、
* 长期记忆

- - -

## 构建方式

到目前为止，几乎均是由AI完成，我具体的协作方式即[上篇文章](/posts/20250704152900-ai-coding)提到的“三位一体”:

* 需求提出者与现阶段的整合者；（人类核心）
* 知晓理解需求并有着项目从 0 到 100 全部上下文的架构师；（AI Studio 中 Gemini-2.5-pro）
* 能够具体地执行架构师要求的工程师（我目前更倾向于使用 VS code 的插件 Augment）。

- - -
