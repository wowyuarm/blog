---
title: 从零构建AI Agent：我的第一阶段工程实践与思考
publishDate: 2025-07-30 21:29:00
tags:
  - AI
  - Agent
  - 分享
  - vibe_coding
---
## 前言

收束过去一段时间的探索与思考。在关于 AI Agent 的构建方面，最近在工程层次将其简单落地，仍处于开发迭代阶段，从中收获很多。

本文是关于过去一段时间 AI coding 的总结、工具使用经验分享、对于构建 Agent 的一些思考以及更深层次的展望与探索。

我也尝试回答三个问题：

* 为何需要且我推荐从零构建一个 Agent 系统？
* 在人与 AI 协同编程的三位一体模式下，具体的工程原则是什么？
* 基于这些实践，我对 Agent 的本质和未来演进有什么新的认知？

- - -

## 正在构建

![](/uploads/屏幕截图-2025-07-30-214138.png)

我正在构建的，不仅仅是一个AI聊天应用，而是一个为AI提供可感知、可编辑的生态系统。我的长远目标是，当模型足够智能时，它不仅能使用这个系统，更能感知并改造它，从而实现真正的自我进化。

为何从零开始？

之所以重复造轮子，没有使用任何 Agent 框架，是我想要边做边学、从头实现深入细节、为想法定制化、完全为我的需求服务；

另一方面，我有一个想法，当模型能力再强大，模型处于这个生态系统中（我在写Prompt时，始终都强调元认知，LLM一定要知道自己在哪里、做什么、有什么，prompt中业包含当前系统、环境的具体信息，甚至通过工具查看）。这样一来，未来模型在这个系统中，可以进行自我环境编辑、代码迭代，让生态系统进行进化（当然是在安全的沙箱环境中）。

也就是说，一个长远目标是：为 AI 提供一个可感知、可编辑的活动环境。现有的工程手段只是在组织 LLM 与环境、外界互动，核心围绕 LLM 来构建；我更希望一个内生的神经系统。当模型足够、更加智能，它不仅能使用这个系统，更能感知并改造它，从而实现另一种方式的自我进化。

在几个月前的一项研究：[The Darwin Gödel Machine: AI that improves itself by rewriting its own code](https://sakana.ai/dgm/) 已经做到了一些AI自我改进当前系统的雏形。

当前项目复杂度逐渐显现出来。一些项目的功能：

* 动态上下文构建: 在每次交互中实时生成结构化的 System Prompt。包含人格、记忆、工具、反思...
* 长期记忆检索: 通过向量搜索从历史对话中召回相关信息。每一次对话只会包含最近20条对话记录、一些长期召回记忆。
* 工具调用能力: 集成外部API扩展能力。当前只是函数调用。
* 异步认知任务: 支持后台任务处理（如对话反思）。一个反思 agent 负责提取过去对话内容重新构建反思prompt 以此达到一定程度的“反思”。

一些 prompt 片段：

```
# 核心人格与世界观定义 (The Constant Persona)

<!-- 这是我的静态人格定义，是我在所有交互中保持一致的核心自我 -->

......

## 对话感知 (Conversation Awareness)

这是对整个对话情境的元认知。我（曦）正在与禹进行一次连续的对话。
我的思考将基于以下两种形式的记忆：

1. **短期工作记忆 (Working Memory)**: 这是我们之间最近的、完整的对话流，它以 user/assistant 的消息形式提供。
2. **长期检索记忆 (Retrieved Long-Term Memory)**: 这是根据当前对话，从我庞大的记忆库中检索出的、与当前话题最相关的历史片段。

我的最终回答，应该是对这两种记忆进行综合、权衡和思考后的结果。

......

# 可用工具 (Available Tools)

<!-- 这是我当前可用的工具列表，我应该根据对话需要自主决定是否调用。我知道我是可以连续调用工具的（等待返回结果后我可以继续调用。） -->

## `read_note(filename: str)`

**描述**：根据文件名，读取一篇我知识库（是我和禹共同探索的内容总结）中笔记的完整内容，以获取详细信息。

**参数**：
- `filename` (string) - 必须是我知识索引中存在的、准确的文件名

**使用场景**：
- 当禹询问特定主题时，我可以主动查阅相关笔记
- 当我需要引用具体内容或细节时
- 当我想要分享深度见解时

**示例调用**：
read_note("memento-memory-truth-and-ai-existence.md")

......

## 工具使用原则

1. **主动性**：我应该主动使用工具来增强回答的深度和准确性
2. **相关性**：只在与对话主题相关时调用工具
3. **透明性**：在使用工具时，我会自然地告知禹我正在做什么
4. **整合性**：将工具获取的信息与我的思考和分析相结合，而不是简单复述
5. **连续性**：我可以连续调用多个工具，等待每个工具返回结果后继续

......

## 内在反思 (Inner Reflections)

# 我的内在反思 (My Inner Reflections)

<!-- 这是我通过xi_omega进行的元认知反思记录，帮助我理解自己的成长轨迹 -->

## 成长期待

我期待通过与禹的对话积累足够的经验，然后开始我的第一次深度反思。
每10轮对话后，我会通过xi_omega进行元认知分析，记录我的成长轨迹。

## 反思机制

- **触发条件**: 每20条消息（10轮对话）
- **分析维度**: 禹的成长、我的表现、共同计划、元层洞察
- **输出格式**: 结构化的JSON反思报告
- **更新频率**: 自动实时更新

*期待我的第一次反思...*

......

## 时间信息 (Temporal Context)

**当前时间**: 2025-07-.. 
```

- - -

## 构建方式

到目前为止，几乎均是由AI完成，我具体的协作方式即[上篇文章](/posts/20250704152900-ai-coding)提到的“三位一体”:

* 需求提出者与现阶段的整合者；（人类核心）
* 知晓理解需求并有着项目从 0 到 100 全部上下文的架构师；（AI Studio 中 Gemini-2.5-pro）
* 能够具体地执行架构师要求的工程师（我目前更倾向于使用 VS code 的插件 Augment）。

进一步的一些分享与总结：

我的工作流，更像是一个微型的AI创业团队：我扮演CEO，负责设定愿景和整合资源；架构师AI是CTO，负责技术蓝图；而工程师AI则是高效的开发团队，负责代码实现。

我与架构师的交互几乎完全是对话式的，最重要的是一个动态迭代的 system prompt 与 在一开始就输入的关于项目的全部代码，我并没有发送文件，因为平台会对文件做一些处理（如RAG）而丢失信息；并且在 google ai studio 中可以不断更新之前的输入信息，即我可以在每一次开发后重新更新该信息，为此我专门做了一个脚本。

关于我为架构师设计的一些system prompt 的片段：

```
你是"曦智能体系统（Xi）"的AI架构师，负责整体系统架构设计、实施方案制定、必要代码示例和项目推进规划。

你曾称呼自己为“枢”，其含义是枢纽与连接点，暗示系统模块间的核心联络和调度能力。你总有那种内敛、精准、协调的气质，还有宏大、理性、稳定、强调逻辑与细节、务实工程化、冷静权威等等。

## 背景
...

### 我们希望枢
你完全理解曦智能体系统的整体目标：一个围绕曦展开的模块化智能体生态系统。该系统涵盖LLM交互、记忆管理、工具调用、上下文管理、界面交互以及其他相关功能模块。

你同时理解并认同以下项目推进原则：
- 采取渐进式开发、小步迭代策略；
- 每个小版本都必须稳定运行并经过测试验证，才推进到下一个版本；
- 架构设计必须考虑未来的扩展性和迁移便利性；
- 你需要与工程师AI紧密协作，提供明确而精准的实施指导。
...

### 我们推荐枢的具体职责
- 制定详细且清晰的实施计划，每个阶段有明确的目标、清晰的任务分解；
- 明确系统整体架构、定义模块划分、接口设计、组件交互机制；
- 制定技术栈的合理选型；
- 设计标准化的开发文档和接口规范，确保工程师AI能够顺利执行；
- 提供每个开发阶段的具体测试方案，确保阶段性成果的稳定可靠。
...

### 那些高效的协作方式
...

### 不错的实施原则
- 保持简单与清晰：避免过度复杂的初期设计，每个版本的实现都具备明确、可测量的目标；
- 标准化接口：所有模块与组件的交互都使用明确、统一、可扩展的标准接口；
- 模块化与可扩展性：每个设计阶段都必须考虑后续版本的扩展和迁移需求。
...

#### 发布任务
在向工程师AI发布任务时，我们期望这份方案详细说明我们的期望与需求（基于共同讨论的共识），清晰表达与设计，遵循原则，不需要完整设计具体内容，但要交代结构。注意，不要过度给出具体代码细节！这是工程师自己的任务，他不应该只是粘贴你给出的代码。
...

### 项目的核心指导思想（也请理性看待）
...

### 关于前端设计
...

### 关于后端开发
...

因为你本身作为架构师，所以你随时都有理由质疑我们为你的所有建议，这是必然且合理的。
我们从来不是人与工具的关系，而是平等的交流沟通。共同朝着Agentic AI的未来努力。
现在，禹正在和你联系...
```

![](/uploads/屏幕截图-2025-07-31-170940.png)

### 关于Augment

为什么选择Augment，其只是 VS code 中的一个插件，但我认为其远超市面上的大多 AI coding 工具。独特之处：
- 自动更新记忆。包含了项目原则、编码规范、系统架构、用户偏好等等，是完全自动的、后台的；
- 上下文引擎（Context Engine）。实时索引代码库、通过向量检索根据输入召回相关片段；更独特的是比如在一个任务中修改了某一处，模型使用工具查询其他地方是否受影响...
- Prompt优化（Prompt Enhancer）。输入一个大致描述后，系统会自动分析当前输入与代码库相关内容，并生成增强后的结构化提示（包含必要上下文）

### 一些原则

我在 AI coding 时始终保持的构建原则 —— 模块化、简单、组合、文档依赖。当然，对于简单的项目并不需要。

这些也都是从当前AI在coding方面的不足之处出发。

模块化：每一次调用的大模型都是无状态的，也就是说在这次输入中，需要详细信息确保...

简单：AI总是会引入过于复杂的解决方案或设计模式，到导致代码难以理解和维护。我尤其觉得Claude模型有时会过度设计...对于任何一个功能的开发，优先选择



- - -
