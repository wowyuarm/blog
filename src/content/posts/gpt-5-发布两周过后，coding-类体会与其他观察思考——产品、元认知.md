---
title: GPT-5 发布两周过后，Coding 类体会与其他观察思考——产品、元认知
publishDate: 2025-08-21 13:18:00
excerpt: 人机协作的智能涌现
tags:
  - AI
  - 深思
  - 分享
  - ""
---
关于 **AI Coding** 中的模型选择，基于近期在 Augment 中的实际使用，我的结论是：GPT-5 在`性价比、复杂任务完成度和可靠性`上表现更优，尤其适合有一定复杂度、需谨慎处理的开发场景。它不仅以更低价格提供了接近 Claude-Sonnet-4 的能力，还在`模糊需求、跨文件修改和长上下文`维护方面更为出色。

Cline 官方评价：

> * 规划时详尽周全，执行时简洁利落
> * 善提精准澄清问题，适时提供多选项方案
> * 具备256k上下文窗口的强记忆与持续追踪能力
> * 擅长差异比对式编辑及多文件协同更改（将持续优化）
> * 执行模式静默专注——代码产出不伴冗余信息

Augment 测试也指出，GPT-5 更擅长跨文件重构、复杂调试类任务，在大型上下文中表现稳定，尤其适合对稳健性和完整性要求较高的小规模修改；

![](/uploads/屏幕截图-2025-08-21-110030.png)

![](/uploads/屏幕截图-2025-08-21-105945.png)

从我自己的使用来看，GPT-5 在 Augment 中**处理问题debug、多文件编辑、谨慎逻辑调整**时确实更可靠，`幻觉少`，`总结质量`（每次任务完成后的详细报告）也很实用。

最初在 GPT-5 刚发布时我曾短暂试用，但由于习惯 Claude 的响应风格（指哪打哪，无需关心实现），一时未适应其`较谨慎`的节奏。当时我在功能开发类任务中更倾向使用 Claude-Sonnet，因它**响应快、修改直接，在意图明确时效率很高**。

但有一些bug，Claude无法解决，我重新回归 GPT-5，其响应速度慢（后台推理），但是效果优秀，总是最小化能够处理bug，且不引入过度设计成分、合理优化其他相关部分（一处修改影响多处，能够找到问题）。

在多次对比中我明确感受到它的优势：`指令遵循更稳定`，尤其强调“最小变更”时违反情况更少，且在大上下文环境中保持`更好的语义一致性`。

在Coding方面，GPT-5既适合vibe coding，交由其任务，哪怕是模糊的需求，也能够处理得不错；也适合结对编程，和他一点点讨论，详细的规划后实施。

不过，Claude 仍然有着不可替代的能力，尤其是 Claude Code 加持下。

- - -

GPT-5风评反转了吗？我想并没有。

刚发布那时我就认为 GPT-5 是一个好产品，智能路由选择模型，但不是一个好模型。

不再是 GPT-4 的惊讶，不再是 o1 的推理范式。

GPT-4.5 的“失败”（尽管这个模型很好用），研究员离职...

OpenAI 不再是 AI lab，而是一家有着取代 Google 的野心的**产品公司**。

尽管GPT-5仍有可圈可点之处，尤其是近一段时间的 Coding 下的体会。

同时，**幻觉少**也是一个很好的一点。GPT-5全系列模型（thinking、mini、nano）幻觉都大幅下降。

- - -

另外一方面，GPT-5在**元认知**方面有独特之处。

我认为一种能力在 AI 时代至关重要。为无状态的 LLM 提供上下文，越详细能力越出色。又要避免少样本示例带来的弊端。

那么，一种`审视与抽离的元认知`视角将很重要。

具体讲，当你能够站在一个`理性视角审视`一件事、计划、任务、一个人，用理性语言将其描述，放在构建的 prompt（上下文）世界中，自会有某种力量切中某些向量间的逻辑关联。

LLM 从无数路径中找出较优的那些，通过详细的**元提示**，有能力催生出超出意外的aha moment

过去的思路（提示词工程，prompt engineering）是尽可能提供清晰的指令和几个例子（少样本学习）。但这只是在教 AI 如何模仿。

而这种元认知方法，是更高维的策略：是在为它构建一个`完整的、逻辑自洽的场景`。

GPT-5 在这种情况下，有着说不清的能力。强大的关联和推理能力，沿着铺设的逻辑路径进行`深度探索`。就好像在解决一个被明确定义的问题，而不是模糊的请求。

这并不是说其有了“自我意识”，仍然是模式匹配。但`长上下文一致性、低幻觉率、指令稳定性`使得其处理全局上下文、细节约束都上升了一个量级。

这会带来一种`人机协作的智能涌现`，人类与模型在上下文中共建的能力。
