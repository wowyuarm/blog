---
title: 流形假说：AI看懂世界，数据之美
publishDate: 2025-04-10 20:32:00
excerpt: |-
  智能的涌现，部分源于对数据内在秩序（流形结构）的深刻学习和高效表示。 
  它并非魔法，而是数据、算法和算力结合的产物。
featuredImage: /uploads/640.jpg
tags:
  - AI
  - 术解
---
“**术解**”专题——从**碎片化阅读**中获得人工智能领域的“**原来如此**”

我们从问题出发，**深入浅出**地剖析，揭示原理，融入**思考**

---

## **01 前言**

关于深度学习，你会知道它是当下人工智能领域最热门的话题，ChatGPT、DeepSeek等大语言模型就是基于**深度学习**技术构建的。

深度学习是人工智能-机器学习下的子领域。机器学习旨在通过学习大量数据中的规律，进而达到面对新数据时做出**预测或分类**。深度学习同样如此，只是它可以通过**神经网络**层层找出、学习数据之间的规律（特征）。

本文从一个**有趣的理论**出发，看一看为什么机器学习（深度学习）中的模型（通过大量学习数据后的具有独特“知识”的程序），能够学习出那些我们人类发现不到的规律，并能够应用。

---

## **02 世界是有规律的**

一条线是一维的，它只有一个方向的变化，这是一个“特征”（x轴）；一个平面，包含长度和宽度，它有两个“特征”。在机器学习中，我们使用“**维度**”指代样本的**特征数量**。

让我们从一张黑白图片说起。每个像素点的亮度值在0（黑）和255（白）之间变化，或者用0到1之间的数值表示。当我们将每个像素看作一个“特征”时，一张图片的维度被定义为它的**像素数量**。

比如，一张100x100（长与宽）像素的黑白图片，我们可以将其视为具有10000个维度的样本。再想象一下，每一个像素点有256（0~255）种取值可能，也就是说一张黑白图片存在**256的10000次方**的组成可能！

然而，事实是这样吗？尽管这张特殊的黑白图片在理论上存在无数的可能，但是现实中是这样吗？你也许会认为随便修改一个像素的亮度值就得到了新的图片，但是这并没有任何意义，因为是**完全无序**的。

我们拍摄到的现实世界图像是由像素点组成的，这一定不是无序的，而是有规律的，这才会诞生“美”与我们看到的世界。

“美”的前提是**数据的有序性**，而不是随意取点的无序！

这是不是因为我们已经看到的，所以把它定义为“有序”？

不是，否则深度学习不会取得现在的成就。就是因为**存在规律、有迹可循**，才有了我们观察的世界、强大的语言模型等等。

我们真正**关心的、有意义的**数据（比如所有**看起来像猫**的那类黑白图片）并不会随机地填满整个10000维空间。

---


## **03 流形假说的美妙**

一张纸是二维的，把它揉成球状放在三维空间中，它的内在维度其实还是二维的。因为如果有一只蚂蚁在上面爬行，它只会向前/后、向左/右，这还是二维平面本身具有的特征。

你看，低维的物体存在于高维的空间中，它们自身形成了特征更少（**维度更低**）、更规则（**更“平滑”**）的形状，这个形状就是“流形”。

流形假说（Manifold Hypothesis）正是基于类似的思想（只不过把物体换成了**数据**）。它假设：我们现实世界中的高维数据（图像、声音、文本等），实际上往往集中分布在一个嵌入在高维空间中的、维度低得多的几何结构上，这个结构就被称为“流形”。

简单说，流形假说就是：真实数据很“抱团”，有**内在规律**，它们在高维空间里其实只占据了一小块有特定形状的、相对简单的区域（流形），而不是像沙子一样撒满整个空间。

就像揉皱的纸是嵌入在三维空间里的二维流形一样，所有“看起来像猫”的100x100像素图片，可能就分布在一个维度远低于10000的流形上。

稍微改变猫的姿态、光照或背景，对应的10000维像素点会在高维空间中移动，但很可能仍然停留在这个“猫流形”或其附近。而那些完全随机、看起来像雪花点的图片，则会远离这个流形。（蚂蚁只会那样移动，**像素点也是**）。

目前而言，无法从理论上证明这一假说的完全成立。不过，还是有一些证据表明数据呈现流形结构的现象并非偶然：

1. **生成过程约束**：比如物理规律、生物进化、语法规则等等，它们约束了数据并非随机产生。其实也反向证明了数据不能无序表示，否则与规律违背。

2. **变化的连续性**：这是说现实世界中的变化是平滑的、连续的。比如一个物体进行旋转，其对应的图片像素值是逐渐变化而不是突然跳转的。

---

## **04 回归主题**

我们回到最初的问题上：为什么机器学习（特别是深度学习模型）能够学习出那些我们人类难以直接发现的规律？

前面我们了解到，**有意义的数据倾向于聚集在嵌入高维空间中的低维流形上**。机器学习模型，尤其是深度学习模型，正是利用了这一点。

**学习流形的“形状”：**模型的训练过程中，在某种意义上，就是在学习这个嵌入在高维空间中的低维流形的几何形状。它试图找到一种方式来“理解”哪些点属于这个流形，哪些点不属于。

深度学习模型就更厉害了，它能够不仅仅是区分“在不在流形上”，更能学到描述这个流形本身的一种**更简洁、更高效**的方式，而且通过神经网络层层抽象来实现的。

模型之所以能够对未见过的新数据做出**预测（泛化）**，正是因为它学到了数据背后的普遍规律——即流形的结构。新的、有意义的数据点，很可能也落在或靠近这个学习到的流形上，模型因此能够对其进行有效处理。

如果数据是完全随机、没有结构的，模型就无法学习，也无法泛化。

---

## **05 原来如此**

当我们惊叹于AI模型能从海量数据中“看懂”图片、“听懂”语音、“读懂”文字时，其背后的一个深刻原理就是**流形假说**。

模型并非真的拥有了人类般的理解力，而是它们通过强大的数学和计算能力，在高维数据空间中捕捉到了数据本身蕴含的、我们肉眼难以察觉的**低维几何结构（流形）**。它们学习的不是孤立的数据点，而是数据点构成的那个有规律、有意义的“形状”。

**模型的力量，正是源于数据自身的结构之美，以及模型发现这种结构的能力。**

---

需要**澄清**，文章主要聚焦于流形假说这一个角度来解释AI的能力。虽然这是一个深刻且重要的原理，但AI（尤其是深度学习）的成功是多种因素综合作用的结果，包括强大的计算能力、海量数据、算法优化等。

来自AI总结：

> 本文解释了AI（特别是深度学习）学习复杂模式的关键在于“流形假说”。该假说认为，高维的真实数据（如图像）并非随机分布，而是倾向于聚集在维度低得多的“流形”几何结构上。有意义的数据点（如各种猫的图片）会位于特定的流形区域，这与无序的随机噪声不同。
>
> 深度学习模型尤其擅长学习这些流形的复杂“形状”或内在规律。通过掌握流形的结构特征，模型能理解数据背后的规律，并实现“泛化”——对落在流形附近的新数据做出准确预测。
>
> 因此，AI的强大主要在于其发现并利用数据内在几何结构的能力，而非具备人类般的理解力。
>
> 文章同时提醒，流形假说是重要因素，但AI的成功还依赖于大数据、算力及算法。
