---
title: AI Evolution Through the Lens of Gall's Law
pubDatetime: 2025-05-24T08:31:00.000Z
tags:
  - AI/ground
  - futureAI
description: Gall's Law tells us that complex systems must evolve from simple systems. The history of AI is precisely a path of inevitable technological accumulation that cannot be skipped.
slug: ai-evolution-through-galls-law
---

Gall's Law states:

> **A complex system that works is invariably found to have evolved from a simple system that worked.**
> A complex system designed from scratch never works and cannot be made to work by patching.

Originally used to describe "evolution over planning" in system design, this law seems particularly fitting when placed in the development trajectory of artificial intelligence.

---

## The Evolution of Neural Networks

Artificial intelligence, especially the development of deep learning, well embodies the path of gradually evolving from simple systems to complex systems.

- From the earliest MP model (1943) to the perceptron (1958), although capabilities were limited, they verified that the basic concept of "simulating neurons" was feasible.
- By the 1980s, the proposal of multi-layer perceptrons and backpropagation algorithms provided a technical foundation for training more complex networks.
- Entering the 2000s, Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) brought practical breakthroughs.
- In 2012, AlexNet ignited the deep learning wave with deep networks and GPU acceleration.
- Subsequent development was even more astonishing: ResNet (2015) solved the deep model degradation problem, Transformer (2017) introduced attention mechanisms and a new paradigm for sequence modeling, completely changing NLP and even the entire AI field.

Every stage is iterative optimization based on existing successful structures, not reinventing the wheel from scratch. Transformer itself is not an architecture "falling from the sky"; its predecessors include Seq2Seq models (2014), Bahdanau attention mechanism (2014), encoder-decoder structures, and more.

The deeper one understands the history of artificial intelligence development, the more one can feel this is an inevitable technological explosion, the accumulation of day-to-day results. Accompanying the improvement of hardware capabilities brings exponential increase in computing power, algorithm improvements, the inevitable expansion of dataâ€”everything is preparing for the scaling law.

---

## The Counterexample of Building from Scratch

In contrast, Japan's "Fifth Generation Computer System" initiative launched in the 1980s provides a typical counterexample that violates Gall's Law.

At that time, to catch up with American AI technology, the Japanese government and enterprises attempted to bypass the traditional von Neumann architecture and directly construct an "intelligent system" based on logical reasoning and knowledge representation, completely detached from existing architectures and experience.

However, despite huge investment, this attempt yielded few results and failed to form any actually sustainable technical path. It attempted to "build a complex system from scratch," violating Gall's Law's evolutionary principle, so failure was perhaps inevitable.

---

## Reinforcement Learning is the Next Step in Evolution

Reinforcement learning (RL) is becoming a new focus in language model development, but this is not a "revolution that overthrows existing architecture," but a natural continuation of evolution.

Sholto Douglas, a core member of the Claude development team, recently stated in an [interview](https://www.youtube.com/watch?v=64lXQP6cs5M):

> In the next 6 to 12 months, we are very focused on scaling up reinforcement learning (RL) and exploring where this will take us. I expect to see extremely rapid progress. There's no need to invest in more orders of magnitude in pre-training scale. Facts have proven that reinforcement learning is effective, and these models will be able to achieve "plug-and-play remote worker" capabilities by 2027.

Previously, OpenAI researcher Yao Shunyu wrote an article [AI Enters the Second Half](https://ysymyth.github.io/The-Second-Half/), saying:

> RL is usually considered the "ultimate form" of AI, after all, in theory it can guarantee winning in games (all competitive tasks in closed environments with clear winners and losers), and in practice, almost all superhuman-level AI systems (like AlphaGo) cannot be separated from RL support.

The introduction of reinforcement learning is further evolution, fine-tuning, and behavioral optimization based on the existing architecture. This approach essentially still follows Gall's Law.

---

## The Enhancement of Intelligence

We might constantly hear voices to "disrupt Transformer," but looking back at AI development history, we find that truly effective progress is always **gradual evolution** based on existing systems. Some current model architectures have been improved on the basis of Transformer, and even fused with other architectures, with deep-level optimization.

As Gall's Law reveals, **a complex system that can work is not designed out of thin air, but grows gradually from a simple system that can work.** Looking forward to reinforcement learning further verifying these.

There is still a long way to go for the enhancement of intelligence. "Intelligence" in my eyes: the ability to complete certain complex goals.
